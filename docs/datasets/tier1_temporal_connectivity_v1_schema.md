# Tier 1 Temporal Connectivity Dataset Schema (v1)

## Overview

This document defines the canonical schema for Tier 1 temporal connectivity datasets generated by `satnet-arch-dss`. These datasets use the Hypatia-based temporal pipeline with SGP4 orbital propagation and GCC-based partition labels.

**Dataset Version:** `tier1_temporal_connectivity_v1`  
**Schema Version:** `1`

## Tables

The dataset consists of two tables:

1. **Runs Table** — One row per simulation run (per-run summary)
2. **Steps Table** — One row per time step per run (time-series data)

---

## Runs Table Schema

| Column | Type | Required | Description |
|--------|------|----------|-------------|
| `run_id` | int | ✓ | Unique identifier for this run (0-indexed) |
| `num_planes` | int | ✓ | Number of orbital planes |
| `sats_per_plane` | int | ✓ | Satellites per orbital plane |
| `total_satellites` | int | ✓ | Total satellites (num_planes × sats_per_plane) |
| `inclination_deg` | float | ✓ | Orbital inclination in degrees |
| `altitude_km` | float | ✓ | Orbital altitude in km |
| `node_failure_prob` | float | ✓ | Node failure probability used for this run |
| `edge_failure_prob` | float | ✓ | Edge failure probability used for this run |
| `duration_minutes` | int | ✓ | Simulation duration in minutes |
| `step_seconds` | int | ✓ | Time step interval in seconds |
| `num_steps` | int | ✓ | Number of time steps in this run |
| `gcc_frac_min` | float | ✓ | Minimum GCC fraction across all time steps |
| `gcc_frac_mean` | float | ✓ | Mean GCC fraction across all time steps |
| `partition_fraction` | float | ✓ | Fraction of steps where network was partitioned |
| `partition_any` | int | ✓ | 1 if partitioned at any step, 0 otherwise |
| `max_partition_streak` | int | ✓ | Longest consecutive run of partitioned steps |
| `num_failed_nodes` | int | ✓ | Number of nodes that failed (persistent) |
| `num_failed_edges` | int | ✓ | Number of edges that failed (from t=0) |
| `failed_nodes_json` | str | ✓ | JSON array of failed node IDs, e.g. `"[1, 5, 12]"` |
| `failed_edges_json` | str | ✓ | JSON array of failed edge tuples, e.g. `"[[0,1], [3,4]]"` |
| `seed` | int | ✓ | Random seed used for this run |
| `config_hash` | str | ✓ | Hash of configuration for reproducibility |
| `schema_version` | int | ✓ | Schema version (must be 1) |
| `dataset_version` | str | ✓ | Dataset version identifier |

### Feature vs Label Columns

**Design-time Features** (inputs for ML models):
- `num_planes`, `sats_per_plane`, `total_satellites`
- `inclination_deg`, `altitude_km`
- `node_failure_prob`, `edge_failure_prob`
- `duration_minutes`, `step_seconds`

**Temporal Aggregate Labels** (outputs from simulation):
- `gcc_frac_min`, `gcc_frac_mean`
- `partition_fraction`, `partition_any`, `max_partition_streak`

**Analysis Columns** (not features, for diagnostics):
- `num_failed_nodes`, `num_failed_edges`

**Graph Reconstruction Columns** (for ML pipeline):
- `failed_nodes_json`, `failed_edges_json`

**Metadata**:
- `run_id`, `seed`, `config_hash`, `schema_version`, `dataset_version`

---

## Steps Table Schema

| Column | Type | Required | Description |
|--------|------|----------|-------------|
| `run_id` | int | ✓ | Foreign key to runs table |
| `t` | int | ✓ | Time step index (0-indexed) |
| `num_nodes` | int | ✓ | Node count in effective graph at this step |
| `num_edges` | int | ✓ | Edge count in effective graph at this step |
| `num_components` | int | ✓ | Number of connected components |
| `gcc_size` | int | ✓ | Size of Giant Connected Component (node count) |
| `gcc_frac` | float | ✓ | Fraction of nodes in GCC (0.0 to 1.0) |
| `partitioned` | int | ✓ | 1 if gcc_frac < threshold, 0 otherwise |

---

## Validation Rules

1. **Required Fields**: All columns marked as required must be present.
2. **Value Ranges**:
   - `gcc_frac`, `gcc_frac_min`, `gcc_frac_mean`: [0.0, 1.0]
   - `partition_fraction`: [0.0, 1.0]
   - `partition_any`, `partitioned`: {0, 1}
   - `num_steps`, `num_nodes`, `num_edges`: ≥ 0
3. **Referential Integrity**: All `run_id` values in steps table must exist in runs table.
4. **Schema Version**: Must equal 1 for this schema version.

---

## Reproducibility

Each run is reproducible given:
- `config_hash`: Deterministic hash of all configuration parameters
- `seed`: Random seed used for failure sampling
- Code version (git SHA recommended)

Rerunning with identical config + seed must produce bit-identical outputs.

---

## Graph Reconstruction Contract (Step 3)

To reconstruct the exact graph sequence for ML training:

1. **Parse epoch**: Use `epoch_iso` (or `DEFAULT_EPOCH_ISO` if missing)
2. **Create adapter**: `HypatiaAdapter(num_planes, sats_per_plane, inclination_deg, altitude_km, epoch=epoch)`
3. **Calculate ISLs**: `adapter.calculate_isls(duration_minutes, step_seconds)`
4. **Parse failures**: `Tier1FailureRealization.from_json_strings(failed_nodes_json, failed_edges_json)`
5. **Apply failures at each step**:
   ```python
   for t, G in adapter.iter_graphs():
       G_eff = G.copy()
       G_eff.remove_nodes_from([n for n in failures.failed_nodes if G_eff.has_node(n)])
       for u, v in failures.failed_edges:
           if G_eff.has_edge(u, v):
               G_eff.remove_edge(u, v)
       # G_eff is now the effective graph at time t
   ```

This ensures regenerated graphs match the `partition_any` labels from simulation.

---

## Example Usage

```python
from satnet.simulation.monte_carlo import (
    Tier1MonteCarloConfig,
    generate_tier1_temporal_dataset,
    runs_to_dicts,
    steps_to_dicts,
)

cfg = Tier1MonteCarloConfig(
    num_runs=100,
    num_planes_range=(3, 6),
    sats_per_plane_range=(4, 8),
    duration_minutes=10,
    step_seconds=60,
    seed=42,
)

runs, steps = generate_tier1_temporal_dataset(cfg)

# Export to dicts for DataFrame/Parquet
runs_dicts = runs_to_dicts(runs)
steps_dicts = steps_to_dicts(steps)
```

---

## Changelog

- **v1.1** (2026-01): Added `failed_nodes_json` and `failed_edges_json` for graph reconstruction contract (Step 3).
- **v1** (2025-12): Initial schema for Tier 1 temporal connectivity with GCC-based labels.
